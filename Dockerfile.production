# Multi-stage build for optimal production deployment
FROM python:3.12-slim as builder

# Set cache directory for Hugging Face models
ENV HF_HOME=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface

# Install build dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    git \
    && rm -rf /var/lib/apt/lists/*

# Create cache directory
RUN mkdir -p /app/.cache/huggingface

# Create virtual environment and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Download BERT models during build (cached layer)
RUN python -c "
import torch
import transformers
from transformers import AutoModel, AutoTokenizer
print('Downloading BERT models...')
try:
    # Download commonly used BERT models
    model_name = 'bert-base-uncased'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    print(f'Successfully downloaded {model_name}')
except Exception as e:
    print(f'Error downloading BERT model: {e}')
    exit(1)
"

# Production stage
FROM python:3.12-slim as production

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PORT=8080
ENV HF_HOME=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface

# Install runtime dependencies only
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create app directory and user
RUN adduser --disabled-password --gecos '' appuser
WORKDIR /app

# Copy Python packages from builder
COPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy cached models from builder
COPY --from=builder /app/.cache /app/.cache

# Copy application code
COPY . .

# Create cache directory and set permissions
RUN mkdir -p /app/.cache/huggingface && \
    chown -R appuser:appuser /app

USER appuser

# Expose port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8080/api/health || exit 1

# Run the application with optimized settings
CMD exec gunicorn \
    --bind :$PORT \
    --workers 1 \
    --threads 8 \
    --timeout 300 \
    --preload \
    --max-requests 1000 \
    --max-requests-jitter 100 \
    app:app